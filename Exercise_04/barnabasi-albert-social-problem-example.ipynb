{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcdb0b6e",
   "metadata": {},
   "source": [
    "# Mesa scale-free networks example - Barabási-Albert model\n",
    "\n",
    "## Description\n",
    "\n",
    "Small-world networks accord with some empirically observed properties of social networks. However, unlike small-world networks, many real-world networks have been observed to have scale-free properties such that some small number of individuals are very highly connected, while most are not.\n",
    "\n",
    "Systems as diverse as genetic networks or the World Wide Web are best described as networks with complex topology.\n",
    "A common property of many large networks is that the vertex connectivities follow a scale-free power-law distribution.\n",
    "\n",
    "This feature was found to be a consequence of two generic mechanisms: \n",
    "1. Networks expand continuously by the addition of new vertices\n",
    "2. New vertices attach preferentially to sites that are already well connected.\n",
    "\n",
    "The development of large networks is governed by robust self-organizing phenomena that go beyond the particulars of the individual systems.\n",
    "\n",
    "Example in molecular biology, where vertices are proteins and genes, the chemical interactions between them repre- senting edges \n",
    "- living systems form a huge genetic network whose vertices are proteins and genes, the chemical interactions between them repre- senting edges\n",
    "- a large network is formed by the nervous system, whose vertices are the nerve cells, connected by axons\n",
    "\n",
    "Example in social science, where vertices are individuals or organiza- tions and the edges are the social interactions between them\n",
    "- The collab- oration graph of movie actors represents a well-documented example of a social net- work. Each actor is represented by a vertex, two actors being connected if they were cast together in the same movie. The probability that an actor has k links (characterizing his or her popularity) has a power-law tail for large k\n",
    "\n",
    "Example in computer science, where\n",
    "- in the World Wide Web (WWW), whose vertices are HTML docu- ments connected by links pointing from one page to another\n",
    "- the rel- atively modest size of the network, contain- ing only 4941 vertices, the scaling region is less prominent but is nevertheless approxi- mated by a power law\n",
    "- In particular, scale-free properties are common in citation networks, scientific collaboration networks, and on the internet. This might correspond, for instance, to scientific communities where some individuals are highly connected, and others are marginally so. [Barabáasi, A.-L., Albert, R.: Emergence of scaling in random networks. Science 286(5439), 509–512 (1999)]\n",
    "- a rather large complex network is formed by the citation patterns of the scientific publications, the ver- tices being papers published in refereed jour- nals and the edges being links to the articles cited in a paper.\n",
    "- the probability that a paper is cited k times (representing the connectivity of a paper within the network) follows a power law with exponent 3.\n",
    "\n",
    "Figure 10 [The Dynamics of Retraction in Epistemic Networks] shows an example of networks for m = 1, 3, 5. We examine networks with m = 1, 2, 3, 4, 5.\n",
    "\n",
    "We found that, across parameter values, retraction is more effective when introduced by the original, founding node. It is not entirely surprising. There are two advantages to a central node issuing a retraction. First, as with the small-world networks, there is an advantage of a retraction coming from the same place because it can chase the same paths the false belief took. Second, there is a benefit when the retraction is issued by a highly connected node, with relatively short paths to the rest of the network.\n",
    "\n",
    "Figure 11 [The Dynamics of Retraction in Epistemic Networks] shows these results for different values of m. Note that when m is low, there is relatively little false belief because the sparse network structure impairs its spread. In all cases, there is a clear benefit to retraction from the original node.\n",
    "\n",
    "Anoter interesting rumors spreading implementation: [Serrano, E., Iglesias, C.A.: Validating viral marketing strategies in Twitter via agent-based social simulation. Expert Syst. Appl. 50(1), 140–150 (2016)]\n",
    "\n",
    "## Model\n",
    "\n",
    "We want to show that, independent of the system and the identity of its constituents, the discribution degree  P(k) - probability that a vertex in the network interacts with k other vertices decays as a power law (remember the binomial degree distribution)\n",
    "This result indicates that large networks self-organize into a scale-free state, a feature unpredicted by all existing random network models.\n",
    "\n",
    "A common feature of the Erno-Renyi and Watts-Strogatz models is that the probability of finding a highly connected vertex (that is, a large k) decreases exponentially with k; thus, vertices with large connectivity are practically absent.\n",
    "\n",
    "In contrast, the power-law tail characterizing P(k) for the networks studied indicates that highly connected (large k) vertices have a large chance of occurring, dominating the connectivity.\n",
    "\n",
    "We use two key features of real-world networks that are responsible for the power-law scaling observed\n",
    "1. Growth\n",
    "2. Preferential attachment\n",
    "\n",
    "### Growth\n",
    "\n",
    "In contrast, most real world networks are open and they form by the continuous addition of new vertices to the system, thus the number of vertices N increases throughout the lifetime of the network. For example, the actor network grows by the addition of new actors to the system, the WWW grows exponentially over time by the addition of new Web pages (8), and the research literature constantly grows by the publication of new papers.\n",
    "Common feature of these systems is that the network continuously expands by the addition of new vertices that are connected to the vertices already present in the system.\n",
    "\n",
    "### Preferential attachment\n",
    "\n",
    "A new actor is most likely to be cast in a supporting role with more established and better-known ac- tors. Consequently, the probability that a new actor will be cast with an established one is much higher than that the new actor will be cast with other less-known actors. Similarly, a newly created Web page will be more likely to include links to well-known popular doc- uments with already-high connectivity, and a new manuscript is more likely to cite a well- known and thus much-cited paper than its less-cited and consequently less-known peer.\n",
    "\n",
    "These examples indicate that the probability with which a new vertex connects to the existing vertices is not uniform; there is a higher probability that it will be linked to a vertex that already has a large number of connections.\n",
    "\n",
    "# Algorithm\n",
    "\n",
    "We now look at networks generated according to the Barabási–Albert preferential-attachment model (Barabási and Albert, 1999).\n",
    "\n",
    "1. The algorithm begins with a connected network of m individual, starting with a small number (m0) of vertices.\n",
    "2. New nodes (up to N ) are added one at a time. To incorporate the growing character of the network, at every time step we add a new vertex with m (<= m0) edges that link the new vertex to m different vertices already present in the system.\n",
    "3. Each new node connects to m existing nodes with probability directly proportional to the number of links the nodes already have. To incorporate preferential attachment, we assume that the probability M that a new vertex will be connected to vertex i depends on the connectivity k i of that vertex.\n",
    "4. Therefore, existing nodes with many links tend to receive more new attachments, e.g., new articles are proportionally more likely to cite ‘famous’ (already heavily cited) articles rather than newer articles with fewer citations.\n",
    "\n",
    "After t time steps, the model leads to a random network with t+m0 vertices and mt edges. This network evolves into a scale-invariant state with the probability that a vertex has k edges, following a power law with an exponent 2.9 +/- 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f260dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesa import Model, Agent\n",
    "from mesa.time import RandomActivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91002358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent\n",
    "class BarnabasiAlbertAgent(Agent):\n",
    "    \n",
    "    def __init__(self, unique_id, opinion, model):\n",
    "        '''\n",
    "         Create a new bounded confidence agent.\n",
    "\n",
    "         Args:\n",
    "            unique_id: Unique identifier for the agent\n",
    "            opinion: An agent's initial opinion\n",
    "        '''\n",
    "        \n",
    "        super().__init__(unique_id, model)\n",
    "        \n",
    "        # 1 Initialization [Your code here]\n",
    "        self.opinion = opinion\n",
    "        \n",
    "    def step(self):\n",
    "        '''\n",
    "        Run one step of the agent.\n",
    "        '''\n",
    "        \n",
    "        # 2 Step agent function\n",
    "\n",
    "        # 3 Randomly chose agent [Your code here]\n",
    "        neighbors_nodes = self.model.grid.get_neighbors(self.unique_id)\n",
    "        neighbors = self.model.grid.get_cell_list_contents(neighbors_nodes)\n",
    "        \n",
    "        if len(neighbors) > 0:\n",
    "            other_agent = self.random.choice(neighbors)\n",
    "\n",
    "            #other_agent = self.random.choice(list(nx.neighbors(self.model.G, self.unique_id)))\n",
    "            #other_agent = self.random.choice(list(nx.all_neighbors(self.model.G, self.unique_id)))\n",
    "            # list gives INT id of node, then still have to selct it, try use NetworkGrid from mesa (check thesis paper)\n",
    "\n",
    "            # 4 Evaluate agents difference of opinion [Your code here]\n",
    "            opinions_distance = abs(self.opinion - other_agent.opinion)\n",
    "\n",
    "            # 5 Re-adjust agents opinions [Your code here]\n",
    "            if self.model.G.has_edge(self.unique_id, other_agent.unique_id) and (opinions_distance < self.model.treshold):\n",
    "                other_agent.opinion = other_agent.opinion + self.model.convergence * (self.opinion - other_agent.opinion)\n",
    "                self.opinion = self.opinion + self.model.convergence * (other_agent.opinion - self.opinion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eff7c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "from mesa.space import NetworkGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "import networkx as nx\n",
    "\n",
    "class BarnabasiAlbertModel(Model):\n",
    "    \n",
    "    def __init__(self, N, treshold, convergence):\n",
    "        '''\n",
    "        Create a new bounded confidence model.\n",
    "\n",
    "         Args:\n",
    "            N: how many agents the model contains\n",
    "            treshold: opinion difference threshold. Floating value from 0 to 1.\n",
    "            convergence: convergence parameter. Floating value from 0 to 0.5.\n",
    "        '''\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # 1 Initialization [Your code here]\n",
    "        self.num_agents = N\n",
    "        self.treshold = treshold\n",
    "        self.convergence = convergence\n",
    "        \n",
    "        self.schedule = RandomActivation(self)\n",
    "        \n",
    "        self.G = nx.barabasi_albert_graph(self.num_agents, 3)  # barabasi_albert parameter\n",
    "        self.grid = NetworkGrid(self.G)\n",
    "        \n",
    "        self.datacollector = DataCollector(    # < Note that we have both an agent and model data collector\n",
    "            model_reporters={\"Treshold\": \"treshold\"}, agent_reporters={\"Opinion\": \"opinion\"}\n",
    "        )\n",
    "        \n",
    "        # 2 Create agents [Your code here]\n",
    "        \n",
    "        #list_of_random_nodes = self.random.sample(self.G.nodes(), self.num_agents)\n",
    "        # give agents random position list_of_random_nodes[i], possiblity not neccesary\n",
    "        \n",
    "        for i in range(self.num_agents):\n",
    "            a = BarnabasiAlbertAgent(i, self.random.random(), self)\n",
    "            self.schedule.add(a)\n",
    "            self.grid.place_agent(a, i)\n",
    "\n",
    "    def step(self):\n",
    "        '''\n",
    "        Run one step of the model. If All agents are happy, halt the model.\n",
    "        '''\n",
    "        \n",
    "        # 3 Step model function\n",
    "        self.datacollector.collect(self)\n",
    "        self.schedule.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d01c71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bounded confidence model ran for 100 steps\n"
     ]
    }
   ],
   "source": [
    "model = BarnabasiAlbertModel(100, 0.5, 0.5)# < Add model parameters [Your code here] )\n",
    "\n",
    "while model.schedule.steps < 100:\n",
    "    model.step()\n",
    "                            \n",
    "print('The bounded confidence model ran for {} steps'.format(model.schedule.steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1c4702",
   "metadata": {},
   "source": [
    "Q1: Visualize the network (small enough) with a barnabasi m parameter 5 (check in the paper)\n",
    "Q1.2: Grow the network by one step (one node) and explain where and why did a new node attach (the growth and prefered attachement)\n",
    "Q2: Plot the Log log  degree distribution for the network, explain the graph\n",
    "Q3: Investigate a number of degree distribution for the newtork in a few timesteps (t=10k -> t=1Million)\n",
    "Do you observe a stable degree distribution for the network regardless of size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
